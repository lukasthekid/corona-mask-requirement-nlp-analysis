{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c65e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from collections import Counter \n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d12d74",
   "metadata": {},
   "source": [
    "Lemmatizing was used in the Preprocessing now we will do word embedding\n",
    "https://stackoverflow.com/questions/23877375/word2vec-lemmatization-of-corpus-before-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8de2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_GodotObject</th>\n",
       "      <th>content</th>\n",
       "      <th>titletext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000115059032</td>\n",
       "      <td>medizinisch Personal Umgang Labor müssen Probe...</td>\n",
       "      <td>Maskenpflicht medizinisch Personal Umgang Coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000116305030</td>\n",
       "      <td>Einführung Maskenpflicht Regierung verschärfen...</td>\n",
       "      <td>schrittweise Einführung Maskenpflicht Öffentli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000116325081</td>\n",
       "      <td>Ende Sicht Regierung setzen Maske bei Einkauf ...</td>\n",
       "      <td>Regierung setzen Maske bei Einkauf Test Freist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000116346340</td>\n",
       "      <td>Supermarkt spätestens ab Montag Entscheidung M...</td>\n",
       "      <td>Maskenpflicht Supermarkt spätestens ab Montag ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000116371728</td>\n",
       "      <td>Clemens Auer italienisch spanisch Verhältnis v...</td>\n",
       "      <td>Sonderbeauftragter Clemens Auer italienisch sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_GodotObject                                            content  \\\n",
       "0   2000115059032  medizinisch Personal Umgang Labor müssen Probe...   \n",
       "1   2000116305030  Einführung Maskenpflicht Regierung verschärfen...   \n",
       "2   2000116325081  Ende Sicht Regierung setzen Maske bei Einkauf ...   \n",
       "3   2000116346340  Supermarkt spätestens ab Montag Entscheidung M...   \n",
       "4   2000116371728  Clemens Auer italienisch spanisch Verhältnis v...   \n",
       "\n",
       "                                           titletext  \n",
       "0  Maskenpflicht medizinisch Personal Umgang Coro...  \n",
       "1  schrittweise Einführung Maskenpflicht Öffentli...  \n",
       "2  Regierung setzen Maske bei Einkauf Test Freist...  \n",
       "3  Maskenpflicht Supermarkt spätestens ab Montag ...  \n",
       "4  Sonderbeauftragter Clemens Auer italienisch sp...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/p_content.csv')\n",
    "df1 = df[['ID_GodotObject','content','titletext']]\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d212b",
   "metadata": {},
   "source": [
    "The model produces high-dimensional vectors, where the size parameter sets the number of dimensions. The optimal number of dimensions depends on the size of the dataset. In our case, 100 dimensions seem to be working very well. min_count parameter controls the minimum frequency of words.\n",
    "\n",
    "\n",
    "\n",
    "https://dylancastillo.co/nlp-snippets-cluster-documents-using-word2vec/\n",
    "\n",
    "\n",
    "## Apply function to remove duplicates\n",
    "\n",
    "\n",
    "Duplicate words can be considered as additional context for the model and can potentially improve the quality of the word embeddings. However, if you have a very large number of duplicates, it may slow down the training process and potentially lead to overfitting. In such cases, it might be beneficial to remove duplicates to speed up training and improve generalization.\n",
    "\n",
    "Overall, whether or not to remove duplicates when using Word2vec will depend on the specific data and the goals of your word embedding task. It is a good idea to try both approaches and see which one gives better results on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e663aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1_/83qhk9ps6fd0yym23nn9nfz00000gn/T/ipykernel_59504/1861739798.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"merged_text\"] = df1[text_columns].apply(lambda x: \" | \".join(x), axis=1)\n",
      "/var/folders/1_/83qhk9ps6fd0yym23nn9nfz00000gn/T/ipykernel_59504/1861739798.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"tokens\"] = df1[\"merged_text\"].map(lambda x: x.split())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_GodotObject</th>\n",
       "      <th>content</th>\n",
       "      <th>titletext</th>\n",
       "      <th>merged_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2000128312219</td>\n",
       "      <td>50 Teilnehmer begräbnissen letzter Abschied se...</td>\n",
       "      <td>VfGH 50 Teilnehmer begräbnissen unverhältnismäßig</td>\n",
       "      <td>50 Teilnehmer begräbnissen letzter Abschied se...</td>\n",
       "      <td>[50, Teilnehmer, begräbnissen, letzter, Abschi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2000120217222</td>\n",
       "      <td>Ampel Wien bleiben Orang acht neu Bezirk Orang...</td>\n",
       "      <td>neu Ampel Wien bleiben Orang acht neu Bezirk O...</td>\n",
       "      <td>Ampel Wien bleiben Orang acht neu Bezirk Orang...</td>\n",
       "      <td>[Ampel, Wien, bleiben, Orang, acht, neu, Bezir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000116717900</td>\n",
       "      <td>Anton bleiben Quarantan fast fünfte freiwillig...</td>\n",
       "      <td>Paznaun Anton bleiben Quarantan fast fünfte fr...</td>\n",
       "      <td>Anton bleiben Quarantan fast fünfte freiwillig...</td>\n",
       "      <td>[Anton, bleiben, Quarantan, fast, fünfte, frei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2000122442386</td>\n",
       "      <td>Antwort wie vieler Mensch Weihnachten Silveste...</td>\n",
       "      <td>wie vieler Mensch Weihnachten Silvester Werkta...</td>\n",
       "      <td>Antwort wie vieler Mensch Weihnachten Silveste...</td>\n",
       "      <td>[Antwort, wie, vieler, Mensch, Weihnachten, Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2000124163685</td>\n",
       "      <td>Anzeige Samstag Polizei nehmen fünf Person fes...</td>\n",
       "      <td>Anzeige Samstag Wien</td>\n",
       "      <td>Anzeige Samstag Polizei nehmen fünf Person fes...</td>\n",
       "      <td>[Anzeige, Samstag, Polizei, nehmen, fünf, Pers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_GodotObject                                            content  \\\n",
       "84   2000128312219  50 Teilnehmer begräbnissen letzter Abschied se...   \n",
       "37   2000120217222  Ampel Wien bleiben Orang acht neu Bezirk Orang...   \n",
       "7    2000116717900  Anton bleiben Quarantan fast fünfte freiwillig...   \n",
       "48   2000122442386  Antwort wie vieler Mensch Weihnachten Silveste...   \n",
       "67   2000124163685  Anzeige Samstag Polizei nehmen fünf Person fes...   \n",
       "\n",
       "                                            titletext  \\\n",
       "84  VfGH 50 Teilnehmer begräbnissen unverhältnismäßig   \n",
       "37  neu Ampel Wien bleiben Orang acht neu Bezirk O...   \n",
       "7   Paznaun Anton bleiben Quarantan fast fünfte fr...   \n",
       "48  wie vieler Mensch Weihnachten Silvester Werkta...   \n",
       "67                               Anzeige Samstag Wien   \n",
       "\n",
       "                                          merged_text  \\\n",
       "84  50 Teilnehmer begräbnissen letzter Abschied se...   \n",
       "37  Ampel Wien bleiben Orang acht neu Bezirk Orang...   \n",
       "7   Anton bleiben Quarantan fast fünfte freiwillig...   \n",
       "48  Antwort wie vieler Mensch Weihnachten Silveste...   \n",
       "67  Anzeige Samstag Polizei nehmen fünf Person fes...   \n",
       "\n",
       "                                               tokens  \n",
       "84  [50, Teilnehmer, begräbnissen, letzter, Abschi...  \n",
       "37  [Ampel, Wien, bleiben, Orang, acht, neu, Bezir...  \n",
       "7   [Anton, bleiben, Quarantan, fast, fünfte, frei...  \n",
       "48  [Antwort, wie, vieler, Mensch, Weihnachten, Si...  \n",
       "67  [Anzeige, Samstag, Polizei, nehmen, fünf, Pers...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_columns = [\"content\", \"titletext\"]\n",
    "df1[\"merged_text\"] = df1[text_columns].apply(lambda x: \" | \".join(x), axis=1)\n",
    "df1[\"tokens\"] = df1[\"merged_text\"].map(lambda x: x.split())\n",
    "\n",
    "# Remove duplicated after preprocessing\n",
    "_, idx = np.unique(df1[\"tokens\"], return_index=True)\n",
    "df1 = df1.iloc[idx, :]\n",
    "\n",
    "print(df1.shape)\n",
    "df1.head()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69befde0-d58e-4fbb-ab8f-be187396bc2f",
   "metadata": {},
   "source": [
    "### Check for common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "425fb8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('der', 808),\n",
       " ('werden', 246),\n",
       " ('Foto', 244),\n",
       " ('in', 221),\n",
       " ('ab', 204),\n",
       " ('Wien', 201),\n",
       " ('gelten', 198),\n",
       " ('sein', 197),\n",
       " ('Maskenpflicht', 194),\n",
       " ('mehr', 191)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = df1[\"merged_text\"].values\n",
    "tokenized_docs = df1[\"tokens\"].values\n",
    "ids = df1[\"ID_GodotObject\"].values\n",
    "vocab = Counter()\n",
    "for token in tokenized_docs:\n",
    "    vocab.update(token)\n",
    "    \n",
    "vocab.most_common(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc8227-dc0e-4489-a2a4-9e24bb24bda5",
   "metadata": {},
   "source": [
    "### Generate Vectors from document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "511bc2ea-1438-4340-8ad4-5cbc1b97a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(list_of_docs, model):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Embedding\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents\n",
    "        model: Gensim's Word Embedding\n",
    "\n",
    "    Returns:\n",
    "        List of document vectors\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5859993d-6022-43ee-bd5f-5e0e517dbd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('der', 0.9998356699943542),\n",
       " ('in', 0.9998061060905457),\n",
       " ('bei', 0.999804675579071),\n",
       " ('werden', 0.9998003840446472),\n",
       " ('mehr', 0.9997920989990234),\n",
       " ('geben', 0.9997724890708923),\n",
       " ('dürfen', 0.9997721314430237),\n",
       " ('neu', 0.9997711181640625),\n",
       " ('können', 0.9997584223747253),\n",
       " ('bleiben', 0.9997560381889343)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(sentences=tokenized_docs, vector_size=100, workers=1, seed=42)\n",
    "model.wv.most_similar(\"Maske\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66832f13-ec2d-4880-ba00-e8772c662b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_docs = vectorize(tokenized_docs, model=model)\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182d711-0012-4b55-82bd-0ac38fc53fbe",
   "metadata": {},
   "source": [
    "NOW TRY TO FIT KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9523d002-5c1b-4f64-87ad-479fd96566a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_GodotObject</th>\n",
       "      <th>cluster_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2000128312219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2000120217222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000116717900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2000122442386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2000124163685</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_GodotObject  cluster_value\n",
       "84   2000128312219              2\n",
       "37   2000120217222              0\n",
       "7    2000116717900              0\n",
       "48   2000122442386              1\n",
       "67   2000124163685              4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "\n",
    "kmeans = KMeans(n_clusters = n)\n",
    "kmeans.fit(vectorized_docs)\n",
    "y_kmeans = kmeans.predict(vectorized_docs)\n",
    "df2 = df1[['ID_GodotObject']].copy()\n",
    "df2['cluster_value'] = y_kmeans\n",
    "df2.to_csv('data/feature/knn_clustering.csv', encoding='utf-8', index=False)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ab7fc-fb54-482d-ba62-57d7e93e659b",
   "metadata": {},
   "source": [
    "now I decided to print the text for each article in each cluster and write the result to a csv file, for later extracting impiortand opinions per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18b62ec8-6a11-4639-bd5e-188886b9152c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3)\n",
      "(27, 3)\n",
      "(5, 3)\n",
      "(16, 3)\n",
      "(24, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n):\n",
    "    rslt_df = df2[df2['cluster_value'] == i].copy()\n",
    "    txt_df = df1[['ID_GodotObject','merged_text']].copy()\n",
    "    rslt_df = pd.merge(rslt_df, txt_df, on=\"ID_GodotObject\")\n",
    "    rslt_df.to_csv('data/feature/clusters/' + str(i) + '_cluster.csv', encoding='utf-8', index=False)\n",
    "    print(rslt_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d136a3d-0306-494d-a142-8056653a0484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
